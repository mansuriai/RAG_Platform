# #automated_platform/app/instance_creator.py

# import os
# import sys
# import shutil
# import json
# from pathlib import Path
# import uuid

# # sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..")))
# from platform_core.config_manager import ConfigManager
# from core.document_processor import EnhancedDocumentProcessor
# from core.embeddings import EmbeddingManager
# from core.vector_store import VectorStore
# from platform_core.deployment import DeploymentManager

# # In automated_platform/app/instance_creator.py
# # from ...core.document_processor import EnhancedDocumentProcessor  # Two levels up then into core
# # from ...core.embeddings import EmbeddingManager
# # from ...core.vector_store import VectorStore

# # # For modules in the same package
# # from ..core.config_manager import ConfigManager  # One level up then into core
# # from ..core.deployment import DeploymentManager

# class InstanceCreator:
#     """Handles the creation of new RAG application instances."""
    
#     def __init__(self):
#         self.config_manager = ConfigManager()
#         self.deployment_manager = DeploymentManager()
        
#     def create_instance(self, instance_id, config, pdf_paths=None, urls=None):
#         """Create a new RAG application instance.
        
#         Args:
#             instance_id (str): Unique identifier for the instance
#             config (dict): Configuration for the instance
#             pdf_paths (list): List of paths to PDF files
#             urls (list): List of URLs to scrape
#         """
#         try:
#             # Create instance directory
#             instance_dir = self.config_manager.get_instance_dir(instance_id)
#             os.makedirs(instance_dir, exist_ok=True)
            
#             # Create required subdirectories
#             os.makedirs(os.path.join(instance_dir, "pdfs"), exist_ok=True)
#             os.makedirs(os.path.join(instance_dir, "data"), exist_ok=True)
            
#             # Setup the instance
#             self._setup_instance_files(instance_id, config)
            
#             # Process PDFs and URLs to generate embeddings
#             if pdf_paths or urls:
#                 self._process_documents(instance_id, config, pdf_paths, urls)
            
#             # Prepare the deployment
#             self.deployment_manager.prepare_deployment(instance_id, config)
            
#             return True
#         except Exception as e:
#             print(f"Error creating instance {instance_id}: {str(e)}")
#             return False
    
#     def _setup_instance_files(self, instance_id, config):
#         """Setup the instance files by copying templates and configuring them."""
#         # Get paths
#         instance_dir = self.config_manager.get_instance_dir(instance_id)
#         template_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "templates"))
        
#         # Create app directory
#         app_dir = os.path.join(instance_dir, "app")
#         os.makedirs(app_dir, exist_ok=True)
        
#         # Copy main app template
#         with open(os.path.join(template_dir, "app_template.py"), 'r') as f:
#             template_content = f.read()
        
#         # Replace placeholders with actual values
#         template_content = template_content.replace("{{APP_TITLE}}", config.get("app_name", "RAG Application"))
#         template_content = template_content.replace("{{INSTANCE_ID}}", instance_id)
        
#         # Write the customized app file
#         with open(os.path.join(app_dir, "main.py"), 'w') as f:
#             f.write(template_content)
        
#         # Create init file
#         with open(os.path.join(app_dir, "__init__.py"), 'w') as f:
#             f.write("# Generated by RAG Application Generator\n")
        
#         # Create a dotenv file for configuration
#         with open(os.path.join(instance_dir, ".env"), 'w') as f:
#             f.write(f"INSTANCE_ID={instance_id}\n")
#             f.write(f"APP_NAME={config.get('app_name', 'RAG Application')}\n")
#             f.write(f"EMBEDDING_MODEL={config.get('embedding_model', 'sentence-transformers/all-mpnet-base-v2')}\n")
#             f.write(f"LLM_MODEL={config.get('llm_model', 'gpt-3.5-turbo')}\n")
#             f.write(f"CHUNK_SIZE={config.get('chunk_size', 1000)}\n")
#             f.write(f"CHUNK_OVERLAP={config.get('chunk_overlap', 200)}\n")
#             f.write(f"TOP_K={config.get('top_k', 5)}\n")
            
#             # Add API keys
#             if "openai_api_key" in config:
#                 f.write(f"OPENAI_API_KEY={config['openai_api_key']}\n")
#             if "anthropic_api_key" in config:
#                 f.write(f"ANTHROPIC_API_KEY={config['anthropic_api_key']}\n")
#             if "pinecone_api_key" in config:
#                 f.write(f"PINECONE_API_KEY={config['pinecone_api_key']}\n")
#                 f.write(f"PINECONE_ENVIRONMENT={config.get('pinecone_environment', 'gcp-starter')}\n")
#                 f.write(f"PINECONE_INDEX_NAME=rag-{instance_id[:8]}\n")
        
#         # Copy necessary utility files
#         # config.py
#         config_py = os.path.join(instance_dir, "utils")
#         os.makedirs(config_py, exist_ok=True)
#         # Create instance-specific config.py
#         with open(os.path.join(config_py, "config.py"), 'w') as f:
#             f.write("import os\n")
#             f.write("from pathlib import Path\n")
#             f.write("from dotenv import load_dotenv\n\n")
#             f.write(f"# Load environment variables from .env file\n")
#             f.write(f"load_dotenv(Path(__file__).parent.parent / '.env')\n\n")
#             f.write("class Config:\n")
#             f.write("    # Application settings\n")
#             f.write("    INSTANCE_ID = os.getenv('INSTANCE_ID')\n")
#             f.write("    APP_TITLE = os.getenv('APP_NAME', 'RAG Application')\n")
#             f.write("    \n")
#             f.write("    # Directory settings\n")
#             f.write("    BASE_DIR = Path(__file__).parent.parent\n")
#             f.write("    DATA_DIR = BASE_DIR / 'data'\n")
#             f.write("    PDF_STORAGE_DIR = BASE_DIR / 'pdfs'\n")
#             f.write("    \n")
#             f.write("    # Model settings\n")
#             f.write("    EMBEDDING_MODEL = os.getenv('EMBEDDING_MODEL', 'sentence-transformers/all-mpnet-base-v2')\n")
#             f.write("    EMBEDDING_DIMENSION = 768  # Default for most sentence transformers models\n")
#             f.write("    LLM_MODEL = os.getenv('LLM_MODEL', 'gpt-3.5-turbo')\n")
#             f.write("    \n")
#             f.write("    # Chunking settings\n")
#             f.write("    CHUNK_SIZE = int(os.getenv('CHUNK_SIZE', 1000))\n")
#             f.write("    CHUNK_OVERLAP = int(os.getenv('CHUNK_OVERLAP', 200))\n")
#             f.write("    TOP_K = int(os.getenv('TOP_K', 5))\n")
#             f.write("    \n")
#             f.write("    # API Keys\n")
#             f.write("    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n")
#             f.write("    ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n")
#             f.write("    \n")
#             f.write("    # Vector Store settings\n")
#             f.write("    PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n")
#             f.write("    PINECONE_ENVIRONMENT = os.getenv('PINECONE_ENVIRONMENT', 'gcp-starter')\n")
#             f.write("    PINECONE_INDEX_NAME = os.getenv('PINECONE_INDEX_NAME', f'rag-{INSTANCE_ID[:8]}')\n")
#             f.write("\n")
#             f.write("config = Config()\n")

#         # Create __init__.py file
#         with open(os.path.join(config_py, "__init__.py"), 'w') as f:
#             f.write("# Generated by RAG Application Generator\n")
        
#         # Copy helpers.py from the original project
#         src_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", "utils"))
#         shutil.copy(os.path.join(src_dir, "helpers.py"), os.path.join(config_py, "helpers.py"))
        
#         # Create core directory and copy necessary files
#         core_dir = os.path.join(instance_dir, "core")
#         os.makedirs(core_dir, exist_ok=True)
        
#         # Copy core modules from original project
#         src_core_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", "core"))
#         core_files = [
#             "document_processor.py",
#             "embeddings.py",
#             "llm.py",
#             "vector_store.py",
#             "web_scraper.py",
#             "__init__.py"
#         ]
        
#         for file in core_files:
#             shutil.copy(os.path.join(src_core_dir, file), os.path.join(core_dir, file))
    
#     def _process_documents(self, instance_id, config, pdf_paths=None, urls=None):
#         """Process documents and generate embeddings.
        
#         Args:
#             instance_id (str): Instance ID
#             config (dict): Instance configuration
#             pdf_paths (list): List of paths to PDF files
#             urls (list): List of URLs to scrape
#         """
#         # Import necessary modules with the instance's config
#         sys.path.insert(0, os.path.join(self.config_manager.get_instance_dir(instance_id)))
        
#         # Now we need to use the instance's modules
#         from utils.config import config as instance_config
        
#         # Initialize document processor
#         doc_processor = EnhancedDocumentProcessor()
        
#         # Initialize embedding manager based on the config
#         embedding_manager = EmbeddingManager(model_name=config.get('embedding_model'))
        
#         # Initialize vector store
#         vector_store = None
#         if config.get('vector_store') == 'Pinecone':
#             vector_store = VectorStore()
#         else:
#             # For other vector stores, we'll need to implement those classes
#             pass
        
#         # Process PDFs
#         if pdf_paths:
#             for pdf_path in pdf_paths:
#                 try:
#                     # Process documents
#                     chunks = doc_processor.process_file(Path(pdf_path))
                    
#                     # Generate embeddings
#                     texts = [chunk['text'] for chunk in chunks]
#                     embeddings = embedding_manager.generate_embeddings(texts)
                    
#                     # Store in vector database
#                     vector_store.add_documents(chunks, embeddings)
#                 except Exception as e:
#                     print(f"Error processing PDF {pdf_path}: {str(e)}")
        
#         # Process URLs
#         if urls:
#             from core.index_website_content import index_website
#             for url in urls:
#                 try:
#                     # Index website content
#                     index_website(url, embedding_manager, vector_store)
#                 except Exception as e:
#                     print(f"Error processing URL {url}: {str(e)}")





############################


# instance_creator

import os
import sys
import shutil
import json
from pathlib import Path
import uuid

# Update this path to include both parent directories
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..")))
from platform_core.config_manager import ConfigManager
from platform_core.deployment import DeploymentManager
from core.document_processor import EnhancedDocumentProcessor
from core.embeddings import EmbeddingManager
from core.vector_store import VectorStore

class InstanceCreator:
    """Handles the creation of new RAG application instances."""
    
    def __init__(self):
        self.config_manager = ConfigManager()
        self.deployment_manager = DeploymentManager()
        
    def create_instance(self, instance_id, config, pdf_paths=None, urls=None):
        """Create a new RAG application instance.
        
        Args:
            instance_id (str): Unique identifier for the instance
            config (dict): Configuration for the instance
            pdf_paths (list): List of paths to PDF files
            urls (list): List of URLs to scrape
        """
        try:
            # Create instance directory
            instance_dir = self.config_manager.get_instance_dir(instance_id)
            os.makedirs(instance_dir, exist_ok=True)
            
            # Create required subdirectories
            os.makedirs(os.path.join(instance_dir, "pdfs"), exist_ok=True)
            os.makedirs(os.path.join(instance_dir, "data"), exist_ok=True)
            
            # Setup the instance
            self._setup_instance_files(instance_id, config)
            
            # Process PDFs and URLs to generate embeddings
            if pdf_paths or urls:
                self._process_documents(instance_id, config, pdf_paths, urls)
            
            # Prepare the deployment
            self.deployment_manager.prepare_deployment(instance_id, config)
            
            return True
        except Exception as e:
            print(f"Error creating instance {instance_id}: {str(e)}")
            return False
    
    def _setup_instance_files(self, instance_id, config):
        """Setup the instance files by copying templates and configuring them."""
        # Get paths
        instance_dir = self.config_manager.get_instance_dir(instance_id)
        template_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "templates"))
        
        # Create app directory
        app_dir = os.path.join(instance_dir, "app")
        os.makedirs(app_dir, exist_ok=True)
        
        # Copy main app template
        with open(os.path.join(template_dir, "app_template.py"), 'r') as f:
            template_content = f.read()
        
        # Replace placeholders with actual values
        template_content = template_content.replace("{{APP_TITLE}}", config.get("app_name", "RAG Application"))
        template_content = template_content.replace("{{INSTANCE_ID}}", instance_id)
        
        # Write the customized app file
        with open(os.path.join(app_dir, "main.py"), 'w') as f:
            f.write(template_content)
        
        # Create init file
        with open(os.path.join(app_dir, "__init__.py"), 'w') as f:
            f.write("# Generated by RAG Application Generator\n")
        
        # Create a dotenv file for configuration
        with open(os.path.join(instance_dir, ".env"), 'w') as f:
            f.write(f"INSTANCE_ID={instance_id}\n")
            f.write(f"APP_NAME={config.get('app_name', 'RAG Application')}\n")
            f.write(f"EMBEDDING_MODEL={config.get('embedding_model', 'sentence-transformers/all-mpnet-base-v2')}\n")
            f.write(f"LLM_MODEL={config.get('llm_model', 'gpt-3.5-turbo')}\n")
            f.write(f"CHUNK_SIZE={config.get('chunk_size', 1000)}\n")
            f.write(f"CHUNK_OVERLAP={config.get('chunk_overlap', 200)}\n")
            f.write(f"TOP_K={config.get('top_k', 5)}\n")
            
            # Add API keys
            if "openai_api_key" in config:
                f.write(f"OPENAI_API_KEY={config['openai_api_key']}\n")
            if "anthropic_api_key" in config:
                f.write(f"ANTHROPIC_API_KEY={config['anthropic_api_key']}\n")
            if "pinecone_api_key" in config:
                f.write(f"PINECONE_API_KEY={config['pinecone_api_key']}\n")
                f.write(f"PINECONE_ENVIRONMENT={config.get('pinecone_environment', 'gcp-starter')}\n")
                f.write(f"PINECONE_INDEX_NAME=rag-{instance_id[:8]}\n")
        
        # Copy necessary utility files
        # config.py
        config_py = os.path.join(instance_dir, "utils")
        os.makedirs(config_py, exist_ok=True)
        # Create instance-specific config.py
        with open(os.path.join(config_py, "config.py"), 'w') as f:
            f.write("import os\n")
            f.write("from pathlib import Path\n")
            f.write("from dotenv import load_dotenv\n\n")
            f.write(f"# Load environment variables from .env file\n")
            f.write(f"load_dotenv(Path(__file__).parent.parent / '.env')\n\n")
            f.write("class Config:\n")
            f.write("    # Application settings\n")
            f.write("    INSTANCE_ID = os.getenv('INSTANCE_ID')\n")
            f.write("    APP_TITLE = os.getenv('APP_NAME', 'RAG Application')\n")
            f.write("    \n")
            f.write("    # Directory settings\n")
            f.write("    BASE_DIR = Path(__file__).parent.parent\n")
            f.write("    DATA_DIR = BASE_DIR / 'data'\n")
            f.write("    PDF_STORAGE_DIR = BASE_DIR / 'pdfs'\n")
            f.write("    \n")
            f.write("    # Model settings\n")
            f.write("    EMBEDDING_MODEL = os.getenv('EMBEDDING_MODEL', 'sentence-transformers/all-mpnet-base-v2')\n")
            f.write("    EMBEDDING_DIMENSION = 768  # Default for most sentence transformers models\n")
            f.write("    LLM_MODEL = os.getenv('LLM_MODEL', 'gpt-3.5-turbo')\n")
            f.write("    \n")
            f.write("    # Chunking settings\n")
            f.write("    CHUNK_SIZE = int(os.getenv('CHUNK_SIZE', 1000))\n")
            f.write("    CHUNK_OVERLAP = int(os.getenv('CHUNK_OVERLAP', 200))\n")
            f.write("    TOP_K = int(os.getenv('TOP_K', 5))\n")
            f.write("    \n")
            f.write("    # API Keys\n")
            f.write("    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n")
            f.write("    ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n")
            f.write("    \n")
            f.write("    # Vector Store settings\n")
            f.write("    PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n")
            f.write("    PINECONE_ENVIRONMENT = os.getenv('PINECONE_ENVIRONMENT', 'gcp-starter')\n")
            f.write("    PINECONE_INDEX_NAME = os.getenv('PINECONE_INDEX_NAME', f'rag-{INSTANCE_ID[:8]}')\n")
            f.write("\n")
            f.write("config = Config()\n")

        # Create __init__.py file
        with open(os.path.join(config_py, "__init__.py"), 'w') as f:
            f.write("# Generated by RAG Application Generator\n")
        
        # Copy helpers.py from the original project
        src_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", "utils"))
        shutil.copy(os.path.join(src_dir, "helpers.py"), os.path.join(config_py, "helpers.py"))
        
        # Create core directory and copy necessary files
        core_dir = os.path.join(instance_dir, "core")
        os.makedirs(core_dir, exist_ok=True)
        
        # Copy core modules from original project
        src_core_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", "core"))
        core_files = [
            "document_processor.py",
            "embeddings.py",
            "llm.py",
            "vector_store.py",
            "web_scraper.py",
            "__init__.py"
        ]
        
        for file in core_files:
            shutil.copy(os.path.join(src_core_dir, file), os.path.join(core_dir, file))
    
    def _process_documents(self, instance_id, config, pdf_paths=None, urls=None):
        """Process documents and generate embeddings.
        
        Args:
            instance_id (str): Instance ID
            config (dict): Instance configuration
            pdf_paths (list): List of paths to PDF files
            urls (list): List of URLs to scrape
        """
        # Import necessary modules with the instance's config
        sys.path.insert(0, os.path.join(self.config_manager.get_instance_dir(instance_id)))
        
        # Now we need to use the instance's modules
        from utils.config import config as instance_config
        
        # Initialize document processor
        doc_processor = EnhancedDocumentProcessor()
        
        # Initialize embedding manager based on the config
        # Remove the model_name parameter since your original EmbeddingManager doesn't accept it
        embedding_manager = EmbeddingManager()
        
        # Initialize vector store
        vector_store = None
        if config.get('vector_store') == 'Pinecone':
            vector_store = VectorStore()
        else:
            # For other vector stores, we'll need to implement those classes
            pass
        
        # Process PDFs
        if pdf_paths:
            for pdf_path in pdf_paths:
                try:
                    # Process documents
                    chunks = doc_processor.process_file(Path(pdf_path))
                    
                    # Generate embeddings
                    texts = [chunk['text'] for chunk in chunks]
                    embeddings = embedding_manager.generate_embeddings(texts)
                    
                    # Store in vector database
                    vector_store.add_documents(chunks, embeddings)
                except Exception as e:
                    print(f"Error processing PDF {pdf_path}: {str(e)}")
        
        # Process URLs
        if urls:
            try:
                # Import here to avoid circular imports
                from core.web_scraper import IndigoWebScraper
                
                scraper = IndigoWebScraper()
                for url in urls:
                    try:
                        # Scrape the URL
                        chunks = scraper.scrape_section("offers")  # Using a default section for now
                        
                        # Generate embeddings
                        texts = [chunk['text'] for chunk in chunks]
                        embeddings = embedding_manager.generate_embeddings(texts)
                        
                        # Store in vector database
                        vector_store.add_documents(chunks, embeddings)
                    except Exception as e:
                        print(f"Error processing URL {url}: {str(e)}")
            except Exception as e:
                print(f"Error initializing scraper: {str(e)}")